{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I am creating so helper functions to help with parsing out our text\n",
    "def clean_soup(soup):\n",
    "    for tag in soup.find_all(['script', 'style','meta']):\n",
    "        tag.decompose()   \n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roland/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/roland/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# This is the hard coded directory in which the raw html lives on my computer\n",
    "rootdir = '/home/roland/Workspace/Data/Procrastinating_HTML/'\n",
    "# Here we are creating a data frame to store the classified information in\n",
    "data = pd.DataFrame(columns = ['activity', 'text', 'timestamp'])\n",
    "\n",
    "# These strings were placed into the HTML by my browser extension to hold onto store the url\n",
    "URL_STRING = \"__URL__: \"\n",
    "HTML_START = \"<\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        f = open(os.path.join(subdir, file))\n",
    "        raw = f.read()\n",
    "        url = ''\n",
    "        # Parsing out the URL string if it exists\n",
    "        if URL_STRING in raw:\n",
    "            url = find_between(raw, URL_STRING, HTML_START)\n",
    "            raw = raw.replace(url, '')\n",
    "        \n",
    "        # Below are characters I am manually parsing out. There must exist a more efficient way to do this\n",
    "        # but for now it runs fast enough.\n",
    "        raw = raw.replace('\\n', ' ')\n",
    "        raw = raw.replace('\\t', ' ')\n",
    "        raw = raw.replace('\\\\n', ' ')\n",
    "        raw = raw.replace('\\\\t', ' ')\n",
    "        raw = raw.replace(URL_STRING, '')\n",
    "\n",
    "        soup = BeautifulSoup(raw)\n",
    "        data.set_value(i, 'text', clean_soup(soup))\n",
    "        t = str(file).split('_')\n",
    "        data.set_value(i, 'activity', t[0])\n",
    "        timestamp = t[1].split('.')[0]\n",
    "        data.set_value(i, 'timestamp', timestamp)\n",
    "        data.set_value(i, 'url', url)\n",
    "        i+=1\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[data.text != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.timestamp = data.timestamp.str.replace(\"\\(1\\)\",\"\")\n",
    "data.timestamp = data.timestamp.str.replace(\"T\",\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[['text','url']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, data.activity,test_size=0.33, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('parsed_html.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
